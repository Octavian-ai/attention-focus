all_input_path: ./experiments/64eea2a/input/all_input.tfrecords
attention_output_activation: tanh
balance_batch: 20
batch_size: 32
debug: false
eval_holdback: 0.1
eval_input_path: ./experiments/64eea2a/input/eval_input.tfrecords
finder_initial_lr: 1.1e-05
input_dir: ./experiments/64eea2a/input
kb_list_size: 78
kb_vector_length: 300
kb_vector_type: croatia
learning_rate: 1.1e-05
limit: null
log_level: INFO
max_gradient_norm: 8
max_steps: 300000
model_dir: ./experiments/64eea2a/model/25658494
modes: [eval, train]
number_of_questions: 2000
output_dir: ./experiments/64eea2a/output
predict_holdback: 0
train_input_path: ./experiments/64eea2a/input/train_input.tfrecords
use_attention_focus: false
use_lr_decay: true
use_lr_finder: false
use_summary_scalar: false
warm_start_dir: null
