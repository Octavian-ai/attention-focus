all_input_path: ./experiments/6fc2d0d/input/all_input.tfrecords
attention_output_activation: abs
balance_batch: 20
batch_size: 32
eval_holdback: 0.1
eval_input_path: ./experiments/6fc2d0d/input/eval_input.tfrecords
finder_initial_lr: 1.0e-06
input_dir: ./experiments/6fc2d0d/input
kb_list_size: 2
kb_vector_length: 12
kb_vector_type: orthogonal
learning_rate: 0.00011183
limit: null
log_level: INFO
max_gradient_norm: 8
max_steps: 300000
model_dir: ./experiments/6fc2d0d/model/25640005
modes: [eval, train]
number_of_questions: 5000
output_dir: ./experiments/6fc2d0d/output
predict_holdback: 0
train_input_path: ./experiments/6fc2d0d/input/train_input.tfrecords
use_attention_focus: true
use_lr_decay: true
use_lr_finder: false
use_summary_scalar: false
warm_start_dir: null
